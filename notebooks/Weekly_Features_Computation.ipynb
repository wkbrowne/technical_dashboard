{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enhanced Weekly Features Computation Pipeline\n",
    "\n",
    "This notebook demonstrates the enhanced weekly features computation process with comprehensive ETF technical analysis.\n",
    "\n",
    "## Enhanced Pipeline Overview\n",
    "\n",
    "The enhanced orchestrator follows this structure for weekly features:\n",
    "1. **Load raw stock and ETF data** using `load_stock_universe()` and `load_etf_universe()`\n",
    "2. **Load enhanced sector mappings** with correlation-validated sector/subsector assignments\n",
    "3. **Enhanced weekly processing** - single parallel job combining:\n",
    "   - Weekly resampling (Friday bars)\n",
    "   - Stock technical features (RSI, MACD, trend, distance)\n",
    "   - ETF technical features (RSI, MACD, 3-day EMA of MACD slope) for:\n",
    "     - SPY (market cap-weighted) & RSP (market equal-weighted)\n",
    "     - Sector ETFs (cap-weighted) & Equal-weight sector ETFs \n",
    "     - Subsector ETFs (22 specialized ETFs like SMH, IBB, XOP)\n",
    "   - Enhanced relative strength analysis\n",
    "   - Weekly prefix addition and data type optimization\n",
    "\n",
    "## Enhanced Features Generated (~150+ per symbol)\n",
    "- **Stock Technical**: RSI, MACD, trend analysis, distance to MAs\n",
    "- **ETF Technical**: RSI, MACD, MACD slope EMA3 for market/sector/subsector ETFs\n",
    "- **Enhanced Relative Strength**: vs SPY, RSP, sectors, equal-weight sectors, subsectors\n",
    "- **Cross-benchmark Analysis**: Sector vs market strength comparisons\n",
    "\n",
    "## Performance Optimization\n",
    "- **Single integrated parallel job** for maximum efficiency\n",
    "- **Enhanced sector mappings** with correlation validation\n",
    "- **Memory optimized** with `float32` types and efficient data structures\n",
    "- **Comprehensive validation** with data quality assessment and visualization dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“ Working directory: /mnt/a61cc0e8-1b32-4574-a771-4ad77e8faab6/conda/technical_dashboard/notebooks\n",
      "ðŸ” Project root: /mnt/a61cc0e8-1b32-4574-a771-4ad77e8faab6/conda/technical_dashboard\n",
      "ðŸ Python path: ['/mnt/a61cc0e8-1b32-4574-a771-4ad77e8faab6/conda/technical_dashboard/src', '/mnt/a61cc0e8-1b32-4574-a771-4ad77e8faab6/conda/technical_dashboard/notebooks/src', '/mnt/a61cc0e8-1b32-4574-a771-4ad77e8faab6/conda/.local/share/mamba/envs/stocks_predictor/lib/python313.zip']...\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "from typing import Dict, Optional, List, Tuple\n",
    "from joblib import Parallel, delayed\n",
    "import logging\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Add project src to path\n",
    "project_root = os.path.abspath('..')\n",
    "if os.path.exists(os.path.join(project_root, 'src')):\n",
    "    sys.path.insert(0, os.path.join(project_root, 'src'))\n",
    "else:\n",
    "    # Try parent directory\n",
    "    parent_dir = os.path.dirname(project_root)\n",
    "    if os.path.exists(os.path.join(parent_dir, 'src')):\n",
    "        sys.path.insert(0, os.path.join(parent_dir, 'src'))\n",
    "\n",
    "print(f\"ðŸ“ Working directory: {os.getcwd()}\")\n",
    "print(f\"ðŸ” Project root: {project_root}\")\n",
    "print(f\"ðŸ Python path: {sys.path[:3]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“ˆ Loading stock universe data...\n"
     ]
    }
   ],
   "source": [
    "# Import existing functions\n",
    "# Import feature functions\n",
    "from features.trend import add_trend_features, add_rsi_features, add_macd_features\n",
    "from features.distance import add_distance_to_ma_features\n",
    "from features.weekly import add_weekly_features_to_daily, _resample_to_weekly, _compute_weekly_features_single_symbol\n",
    "from features.relstrength import _compute_relative_strength_block\n",
    "\n",
    "# Import data loading functions\n",
    "from data.loader import load_stock_universe, load_etf_universe\n",
    "\n",
    "# Import daily feature processing functions (from orchestrator)\n",
    "from features.assemble import assemble_indicators_from_wide\n",
    "from features.volatility import add_multiscale_vol_regime\n",
    "# from features.hurst import add_hurst_features\n",
    "from features.range_breakout import add_range_breakout_features\n",
    "from features.volume import add_volume_features, add_volume_shock_features\n",
    "from features.ohlc_adjustment import adjust_ohlc_to_adjclose\n",
    "\n",
    "print(\"ðŸ“ˆ Loading stock universe data...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ’¾ stocks: loading cache /mnt/a61cc0e8-1b32-4574-a771-4ad77e8faab6/conda/technical_dashboard/cache/stock_data_universe.parquet\n",
      "ðŸ“Š Available data keys: ['AdjClose', 'Close', 'High', 'Low', 'Open', 'Volume']\n",
      "âœ… Converted to long format: 2953 symbols with 3,386,297 total daily bars\n",
      "ðŸ“… Date range: 2020-09-21 00:00:00 to 2025-09-19 00:00:00\n",
      "ðŸ” Sample symbols: ['A', 'AA', 'AACB', 'AACI', 'AACT', 'AAL', 'AAMI', 'AAOI', 'AAON', 'AAP']\n",
      "ðŸ“Š Columns: ['date', 'symbol', 'adjclose', 'close', 'high', 'low', 'open', 'volume']\n",
      "âš ï¸ Found 270 missing values\n"
     ]
    }
   ],
   "source": [
    "stock_data_dict = load_stock_universe()                                                                                     \n",
    "                                                                                                                                  \n",
    "if stock_data_dict is not None and isinstance(stock_data_dict, dict):                                                       \n",
    "    # Check available keys                                                                                                  \n",
    "    available_keys = list(stock_data_dict.keys())                                                                           \n",
    "    print(f\"ðŸ“Š Available data keys: {available_keys}\")                                                                      \n",
    "                                                                                                                            \n",
    "    # Convert wide format dictionaries to long format DataFrame                                                             \n",
    "    dfs_to_concat = []                                                                                                      \n",
    "                                                                                                                            \n",
    "    for price_type, wide_df in stock_data_dict.items():                                                                     \n",
    "        if wide_df.empty:\n",
    "            continue\n",
    "\n",
    "        # Convert wide format to long format\n",
    "        long_df = wide_df.reset_index().melt(\n",
    "            id_vars='date',\n",
    "            var_name='symbol',\n",
    "            value_name=price_type.lower()\n",
    "        )\n",
    "        long_df = long_df.dropna(subset=[price_type.lower()])\n",
    "        dfs_to_concat.append(long_df.set_index(['date', 'symbol']))\n",
    "\n",
    "    if dfs_to_concat:\n",
    "        # Combine all price types into single DataFrame\n",
    "        df_daily = pd.concat(dfs_to_concat, axis=1).reset_index()\n",
    "\n",
    "        # Rename columns to standard format\n",
    "        column_mapping = { \n",
    "            'adjclose': 'adjclose',\n",
    "            'close': 'close',\n",
    "            'high': 'high',\n",
    "            'low': 'low',\n",
    "            'open': 'open',\n",
    "            'volume': 'volume'\n",
    "        }\n",
    "        df_daily = df_daily.rename(columns=column_mapping)\n",
    "\n",
    "        # Remove any rows with all NaN values\n",
    "        df_daily = df_daily.dropna(how='all', subset=['open', 'high', 'low', 'close', 'adjclose', 'volume'])\n",
    "\n",
    "        symbols = df_daily['symbol'].unique()\n",
    "        date_range = f\"{df_daily['date'].min()} to {df_daily['date'].max()}\"\n",
    "\n",
    "        print(f\"âœ… Converted to long format: {len(symbols)} symbols with {len(df_daily):,} total daily bars\")\n",
    "        print(f\"ðŸ“… Date range: {date_range}\")\n",
    "        print(f\"ðŸ” Sample symbols: {list(symbols[:10])}\")\n",
    "        print(f\"ðŸ“Š Columns: {list(df_daily.columns)}\")\n",
    "\n",
    "        # Check data quality\n",
    "        missing_data = df_daily.isnull().sum().sum()\n",
    "        if missing_data > 0:\n",
    "            print(f\"âš ï¸ Found {missing_data:,} missing values\")\n",
    "        else:\n",
    "            print(\"âœ… No missing values detected\")\n",
    "    else:\n",
    "          print(\"âŒ Failed to load stock data or unexpected format returned\")\n",
    "          df_daily = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”§ Enhanced Weekly Stock Features Function Created (with wk_ prefix)\n",
      "   ðŸ“Š Features computed:\n",
      "     - Weekly OHLCV resampling (Friday bars)\n",
      "     - wk_rsi_* (6, 14, 21 periods)\n",
      "     - wk_macd_* (5/12/4) + wk_macd_slope_ema3\n",
      "     - wk_trend_* and wk_ma_* (trend analysis)\n",
      "     - wk_dist_* (distance to moving averages)\n",
      "     - wk_vol_* (multiscale volatility regime)\n",
      "     - wk_hurst_* (trend persistence)\n",
      "     - wk_range_* (breakout features)\n",
      "     - wk_volume_* (volume and shock features)\n",
      "\n",
      "ðŸ§ª Testing with 2 symbols: ['A', 'AA']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-18 11:43:26,579 - __main__ - ERROR - Error computing weekly stock features for A: add_multiscale_vol_regime() got an unexpected keyword argument 'src_col'\n",
      "2025-10-18 11:43:26,790 - __main__ - ERROR - Error computing weekly stock features for AA: add_multiscale_vol_regime() got an unexpected keyword argument 'src_col'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   âŒ A: Failed to generate features\n",
      "   âŒ AA: Failed to generate features\n",
      "\n",
      "âœ… Enhanced weekly stock features function ready for parallel processing\n"
     ]
    }
   ],
   "source": [
    "def compute_weekly_stock_features(df_symbol: pd.DataFrame, symbol: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Compute weekly resampled stock data with comprehensive technical features.\n",
    "    \n",
    "    Args:\n",
    "        df_symbol: Daily OHLCV data for one symbol \n",
    "        symbol: Symbol name\n",
    "        \n",
    "    Returns:\n",
    "        Weekly DataFrame with stock technical features (all prefixed with wk_)\n",
    "    \"\"\"\n",
    "    if df_symbol.empty or 'date' not in df_symbol.columns:\n",
    "        logger.warning(f\"Empty or invalid data for {symbol}\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    try:\n",
    "        # Step 1: Weekly resampling\n",
    "        df_symbol = df_symbol.copy()\n",
    "        df_symbol['date'] = pd.to_datetime(df_symbol['date'])\n",
    "        df_weekly = df_symbol.set_index('date').copy()\n",
    "        \n",
    "        # Aggregation rules for OHLCV\n",
    "        agg_rules = {\n",
    "            'open': 'first',\n",
    "            'high': 'max', \n",
    "            'low': 'min',\n",
    "            'close': 'last',\n",
    "            'adjclose': 'last',\n",
    "            'volume': 'sum'\n",
    "        }\n",
    "        \n",
    "        # Resample to weekly Friday bars\n",
    "        weekly_data = df_weekly.resample('W-FRI').agg(agg_rules)\n",
    "        weekly_data = weekly_data.dropna(subset=['close'])\n",
    "        \n",
    "        if weekly_data.empty or len(weekly_data) < 30:\n",
    "            logger.warning(f\"Insufficient weekly data for {symbol}: {len(weekly_data)} bars\")\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        # Add required columns\n",
    "        weekly_data['week_end'] = weekly_data.index\n",
    "        weekly_data['symbol'] = symbol\n",
    "        \n",
    "        # Calculate weekly returns\n",
    "        src_col = 'adjclose' if 'adjclose' in weekly_data.columns else 'close'\n",
    "        weekly_data['ret'] = np.log(pd.to_numeric(weekly_data[src_col], errors='coerce')).diff()\n",
    "        \n",
    "        weekly_data = weekly_data.reset_index(drop=True)\n",
    "        \n",
    "        # Store original columns to identify new features for prefixing\n",
    "        original_cols = set(weekly_data.columns)\n",
    "        \n",
    "        # Step 2: Stock Technical Features\n",
    "        \n",
    "        # RSI features (6, 14, 21 week periods)\n",
    "        weekly_data = add_rsi_features(\n",
    "            weekly_data, \n",
    "            src_col=src_col, \n",
    "            periods=(6, 14, 21)\n",
    "        )\n",
    "        \n",
    "        # MACD features (weekly: fast=5, slow=12, signal=4)\n",
    "        weekly_data = add_macd_features(\n",
    "            weekly_data,\n",
    "            src_col=src_col,\n",
    "            fast=5, slow=12, signal=4,\n",
    "            derivative_ema_span=2\n",
    "        )\n",
    "        \n",
    "        # Add 3-period EMA of MACD slope if MACD slope exists\n",
    "        macd_slope_cols = [col for col in weekly_data.columns if 'macd_slope' in col]\n",
    "        for macd_slope_col in macd_slope_cols:\n",
    "            if not weekly_data[macd_slope_col].empty:\n",
    "                ema3_col = f\"{macd_slope_col}_ema3\"\n",
    "                weekly_data[ema3_col] = weekly_data[macd_slope_col].ewm(span=3, min_periods=2).mean()\n",
    "        \n",
    "        # Trend features\n",
    "        weekly_data = add_trend_features(\n",
    "            weekly_data,\n",
    "            src_col=src_col,\n",
    "            ma_periods=(20, 50),  \n",
    "            slope_window=8,\n",
    "            eps=1e-5\n",
    "        )\n",
    "        \n",
    "        # Distance to MA features\n",
    "        weekly_data = add_distance_to_ma_features(\n",
    "            weekly_data,\n",
    "            src_col=src_col,\n",
    "            ma_lengths=(8, 21, 40),\n",
    "            z_window=26\n",
    "        )\n",
    "        \n",
    "        # Step 3: Advanced Features\n",
    "        \n",
    "        # Multiscale volatility regime features\n",
    "        weekly_data = add_multiscale_vol_regime(weekly_data, src_col=src_col)\n",
    "        \n",
    "        # Hurst exponent features for trend persistence\n",
    "        weekly_data = add_hurst_features(weekly_data, src_col=src_col)\n",
    "        \n",
    "        # Range breakout features\n",
    "        weekly_data = add_range_breakout_features(weekly_data, src_col=src_col)\n",
    "        \n",
    "        # Volume features (if volume data available)\n",
    "        if 'volume' in weekly_data.columns and not weekly_data['volume'].isna().all():\n",
    "            weekly_data = add_volume_features(weekly_data, src_col=src_col)\n",
    "            weekly_data = add_volume_shock_features(weekly_data, src_col=src_col)\n",
    "        \n",
    "        # Step 4: Add weekly prefix to all new features\n",
    "        new_cols = set(weekly_data.columns) - original_cols\n",
    "        feature_cols_to_rename = [col for col in new_cols \n",
    "                                 if col not in ['week_end', 'symbol', 'ret'] and not col.startswith('wk_')]\n",
    "        \n",
    "        rename_dict = {col: f\"wk_{col}\" for col in feature_cols_to_rename}\n",
    "        weekly_data = weekly_data.rename(columns=rename_dict)\n",
    "        \n",
    "        logger.debug(f\"Computed weekly stock features for {symbol}: {len(weekly_data)} rows, {len(rename_dict)} wk_ features\")\n",
    "        return weekly_data\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error computing weekly stock features for {symbol}: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "\n",
    "# Test the function with a small sample\n",
    "print(\"ðŸ”§ Enhanced Weekly Stock Features Function Created (with wk_ prefix)\")\n",
    "print(\"   ðŸ“Š Features computed:\")\n",
    "print(\"     - Weekly OHLCV resampling (Friday bars)\")\n",
    "print(\"     - wk_rsi_* (6, 14, 21 periods)\")\n",
    "print(\"     - wk_macd_* (5/12/4) + wk_macd_slope_ema3\")\n",
    "print(\"     - wk_trend_* and wk_ma_* (trend analysis)\")\n",
    "print(\"     - wk_dist_* (distance to moving averages)\")\n",
    "print(\"     - wk_vol_* (multiscale volatility regime)\")\n",
    "print(\"     - wk_hurst_* (trend persistence)\")\n",
    "print(\"     - wk_range_* (breakout features)\")\n",
    "print(\"     - wk_volume_* (volume and shock features)\")\n",
    "\n",
    "# Test with first few symbols if data is available\n",
    "try:\n",
    "    if 'df_daily' in locals() and not df_daily.empty:\n",
    "        test_symbols = df_daily['symbol'].unique()[:2]\n",
    "        print(f\"\\nðŸ§ª Testing with {len(test_symbols)} symbols: {list(test_symbols)}\")\n",
    "        \n",
    "        for test_symbol in test_symbols:\n",
    "            test_data = df_daily[df_daily['symbol'] == test_symbol].copy()\n",
    "            result = compute_weekly_stock_features(test_data, test_symbol)\n",
    "            \n",
    "            if not result.empty:\n",
    "                wk_features = [col for col in result.columns if col.startswith('wk_')]\n",
    "                print(f\"   âœ… {test_symbol}: {len(result)} weekly bars, {len(wk_features)} wk_ features\")\n",
    "                print(f\"      ðŸ“‹ Sample features: {wk_features[:5]}...\")\n",
    "            else:\n",
    "                print(f\"   âŒ {test_symbol}: Failed to generate features\")\n",
    "        \n",
    "        print(\"\\nâœ… Enhanced weekly stock features function ready for parallel processing\")\n",
    "    else:\n",
    "        print(\"\\nâ³ Waiting for daily data to be loaded for testing\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nâš ï¸ Testing skipped: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”§ Weekly ETF Features Function Created\n",
      "   ðŸ“Š Features computed:\n",
      "     - Weekly OHLCV resampling (Friday bars)\n",
      "     - RSI (6, 14, 21 periods)\n",
      "     - MACD (5/12/4) + 3-day EMA of MACD slope\n",
      "     - Optimized for ETF benchmarking in relative strength\n",
      "\n",
      "â³ No ETF symbols found in data for testing\n",
      "\n",
      "âœ… Step 3B completed: Weekly ETF features function ready for benchmarking\n"
     ]
    }
   ],
   "source": [
    "def compute_weekly_etf_features(df_etf: pd.DataFrame, symbol: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Compute weekly resampled ETF data with technical features.\n",
    "    \n",
    "    Args:\n",
    "        df_etf: Daily OHLCV data for one ETF symbol\n",
    "        symbol: ETF symbol name\n",
    "        \n",
    "    Returns:\n",
    "        Weekly DataFrame with ETF technical features\n",
    "    \"\"\"\n",
    "    if df_etf.empty or 'date' not in df_etf.columns:\n",
    "        logger.warning(f\"Empty or invalid data for ETF {symbol}\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    try:\n",
    "        # Step 1: Weekly resampling\n",
    "        df_etf = df_etf.copy()\n",
    "        df_etf['date'] = pd.to_datetime(df_etf['date'])\n",
    "        df_weekly = df_etf.set_index('date').copy()\n",
    "        \n",
    "        # Aggregation rules for OHLCV\n",
    "        agg_rules = {\n",
    "            'open': 'first',\n",
    "            'high': 'max', \n",
    "            'low': 'min',\n",
    "            'close': 'last',\n",
    "            'adjclose': 'last',\n",
    "            'volume': 'sum'\n",
    "        }\n",
    "        \n",
    "        # Resample to weekly Friday bars\n",
    "        weekly_data = df_weekly.resample('W-FRI').agg(agg_rules)\n",
    "        weekly_data = weekly_data.dropna(subset=['close'])\n",
    "        \n",
    "        if weekly_data.empty or len(weekly_data) < 30:\n",
    "            logger.warning(f\"Insufficient weekly data for ETF {symbol}: {len(weekly_data)} bars\")\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        # Add required columns\n",
    "        weekly_data['week_end'] = weekly_data.index\n",
    "        weekly_data['symbol'] = symbol\n",
    "        \n",
    "        # Calculate weekly returns\n",
    "        src_col = 'adjclose' if 'adjclose' in weekly_data.columns else 'close'\n",
    "        weekly_data['ret'] = np.log(pd.to_numeric(weekly_data[src_col], errors='coerce')).diff()\n",
    "        \n",
    "        weekly_data = weekly_data.reset_index(drop=True)\n",
    "        \n",
    "        # Step 2: ETF Technical Features\n",
    "        \n",
    "        # RSI features (6, 14, 21 week periods)\n",
    "        weekly_data = add_rsi_features(\n",
    "            weekly_data, \n",
    "            src_col=src_col, \n",
    "            periods=(6, 14, 21)\n",
    "        )\n",
    "        \n",
    "        # MACD features (weekly: fast=5, slow=12, signal=4)\n",
    "        weekly_data = add_macd_features(\n",
    "            weekly_data,\n",
    "            src_col=src_col,\n",
    "            fast=5, slow=12, signal=4,\n",
    "            derivative_ema_span=2\n",
    "        )\n",
    "        \n",
    "        # Add 3-day EMA of MACD slope (critical for ETF relative strength analysis)\n",
    "        macd_slope_cols = [col for col in weekly_data.columns if 'macd_slope' in col]\n",
    "        for macd_slope_col in macd_slope_cols:\n",
    "            if not weekly_data[macd_slope_col].empty:\n",
    "                ema3_col = f\"{macd_slope_col}_ema3\"\n",
    "                weekly_data[ema3_col] = weekly_data[macd_slope_col].ewm(span=3, min_periods=2).mean()\n",
    "        \n",
    "        logger.debug(f\"Computed weekly ETF features for {symbol}: {len(weekly_data)} rows, {len(weekly_data.columns)} features\")\n",
    "        return weekly_data\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error computing weekly ETF features for {symbol}: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "\n",
    "# Test the function\n",
    "print(\"ðŸ”§ Weekly ETF Features Function Created\")\n",
    "print(\"   ðŸ“Š Features computed:\")\n",
    "print(\"     - Weekly OHLCV resampling (Friday bars)\")\n",
    "print(\"     - RSI (6, 14, 21 periods)\")\n",
    "print(\"     - MACD (5/12/4) + 3-day EMA of MACD slope\")\n",
    "print(\"     - Optimized for ETF benchmarking in relative strength\")\n",
    "\n",
    "# Test with ETF symbols if data is available\n",
    "try:\n",
    "    if 'df_daily' in locals() and not df_daily.empty:\n",
    "        etf_symbols = [sym for sym in df_daily['symbol'].unique() \n",
    "                      if sym in ['SPY', 'RSP', 'XLK', 'XLF', 'XLE']][:3]\n",
    "        \n",
    "        if etf_symbols:\n",
    "            print(f\"\\nðŸ§ª Testing with {len(etf_symbols)} ETF symbols: {list(etf_symbols)}\")\n",
    "            \n",
    "            for test_etf in etf_symbols:\n",
    "                test_data = df_daily[df_daily['symbol'] == test_etf].copy()\n",
    "                result = compute_weekly_etf_features(test_data, test_etf)\n",
    "                \n",
    "                if not result.empty:\n",
    "                    technical_cols = [col for col in result.columns \n",
    "                                    if any(feat in col for feat in ['rsi_', 'macd_', 'ema3'])]\n",
    "                    print(f\"   âœ… {test_etf}: {len(result)} weekly bars, {len(technical_cols)} technical features\")\n",
    "                else:\n",
    "                    print(f\"   âŒ {test_etf}: Failed to generate features\")\n",
    "        else:\n",
    "            print(\"\\nâ³ No ETF symbols found in data for testing\")\n",
    "        \n",
    "        print(\"\\nâœ… Step 3B completed: Weekly ETF features function ready for benchmarking\")\n",
    "    else:\n",
    "        print(\"\\nâ³ Waiting for daily data to be loaded for testing\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nâš ï¸ Testing skipped: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Clean Weekly Stock Features Function\n",
    "\n",
    "Let's create a focused function that computes weekly resampled stock data with technical features."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

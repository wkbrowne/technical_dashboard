{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# Streamlined Training Pipeline\n",
    "\n",
    "**Updated to use Integer-Based Regime System**\n",
    "\n",
    "**Training Flow:**\n",
    "1. Configure regime settings (integer states)\n",
    "2. Load all data\n",
    "3. Train global Markov model on all data\n",
    "4. Train individual Markov models on specific stocks using global prior\n",
    "5. Train close price KDE globally then stock-specific\n",
    "6. Train open price model with trend/volatility resolved KDEs\n",
    "7. Train high/low copulas based on close/open prices\n",
    "8. Train ARIMA-GARCH models on BB and 20-day MA\n",
    "9. Make prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "setup",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Starting streamlined training pipeline - 20:51:37\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "sys.path.append('../src')\n",
    "\n",
    "print(f\"🚀 Starting streamlined training pipeline - {datetime.now().strftime('%H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "y3hqebd8a2j",
   "metadata": {},
   "source": [
    "## 🔧 Regime Configuration\n",
    "\n",
    "**Configure the integer-based regime system at the top of the pipeline**\n",
    "\n",
    "## 🌍 New Feature: US Universe Data Loading\n",
    "\n",
    "**The pipeline now supports loading data from the US universe file (5013 stocks)**\n",
    "- **File**: `cache/US universe_2025-08-05_a782c.csv` \n",
    "- **Usage**: Uncomment the optional data loading section in Step 1\n",
    "- **Benefits**: Train models on complete US stock universe instead of subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "rpj2v8upky",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎛️ REGIME CONFIGURATION\n",
      "==================================================\n",
      "Trend States: 7\n",
      "Volatility States: 5\n",
      "Total Regimes: 35\n",
      "\n",
      "🔄 Creating custom regime configuration...\n",
      "✅ Custom configuration applied\n",
      "\n",
      "📊 Regime Details:\n",
      "   Trend states: [0, 1, 2, 3, 4]\n",
      "   Trend labels: ['strong_bear', 'bear', 'sideways', 'bull', 'strong_bull']\n",
      "   Vol states: [0, 1, 2]\n",
      "   Vol labels: ['low', 'medium', 'high']\n",
      "\n",
      "🔗 Example Combined Regimes:\n",
      "   First 5: ['strong_bear_low', 'strong_bear_medium', 'strong_bear_high', 'bear_low', 'bear_medium']\n",
      "   Last 5: ['bull_medium', 'bull_high', 'strong_bull_low', 'strong_bull_medium', 'strong_bull_high']\n",
      "\n",
      "🔄 State-Label Examples:\n",
      "   trend_0 = strong_bear\n",
      "   trend_4 = strong_bull\n",
      "   vol_0 = low\n",
      "   vol_2 = high\n",
      "\n",
      "✅ Regime configuration complete - ready for training\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# =====================================================\n",
    "# REGIME CONFIGURATION - MODIFY THESE SETTINGS\n",
    "# =====================================================\n",
    "\n",
    "# Set the number of regime states to use\n",
    "N_TREND_STATES = 7    # Number of trend states (3, 5, 7, etc.)\n",
    "N_VOL_STATES = 5      # Number of volatility states (2, 3, 5, etc.)\n",
    "\n",
    "print(f\"🎛️ REGIME CONFIGURATION\")\n",
    "print(f\"=\" * 50)\n",
    "print(f\"Trend States: {N_TREND_STATES}\")\n",
    "print(f\"Volatility States: {N_VOL_STATES}\")\n",
    "print(f\"Total Regimes: {N_TREND_STATES * N_VOL_STATES}\")\n",
    "\n",
    "# Apply the configuration to the global regime system\n",
    "sys.path.append('../src')\n",
    "from config.regime_config import create_regime_config, set_custom_regime_config, REGIME_CONFIG\n",
    "\n",
    "# Create custom regime configuration with specified states\n",
    "if N_TREND_STATES != 5 or N_VOL_STATES != 3:\n",
    "    print(f\"\\n🔄 Creating custom regime configuration...\")\n",
    "    custom_config = create_regime_config(n_trend_states=N_TREND_STATES, n_vol_states=N_VOL_STATES)\n",
    "    set_custom_regime_config(custom_config)\n",
    "    print(f\"✅ Custom configuration applied\")\n",
    "else:\n",
    "    print(f\"\\n✅ Using default configuration (5×3)\")\n",
    "\n",
    "# Show regime details\n",
    "config = REGIME_CONFIG\n",
    "print(f\"\\n📊 Regime Details:\")\n",
    "print(f\"   Trend states: {config.trend.get_all_states()}\")\n",
    "print(f\"   Trend labels: {config.trend.get_all_labels()}\")\n",
    "print(f\"   Vol states: {config.volatility.get_all_states()}\")  \n",
    "print(f\"   Vol labels: {config.volatility.get_all_labels()}\")\n",
    "\n",
    "# Show some example regimes\n",
    "combined_regimes = config.get_all_combined_regimes()\n",
    "print(f\"\\n🔗 Example Combined Regimes:\")\n",
    "print(f\"   First 5: {combined_regimes[:5]}\")\n",
    "print(f\"   Last 5: {combined_regimes[-5:]}\")\n",
    "\n",
    "# Show state-to-label conversion examples\n",
    "print(f\"\\n🔄 State-Label Examples:\")\n",
    "print(f\"   trend_0 = {config.trend.get_state_label(0)}\")\n",
    "print(f\"   trend_{config.trend.get_all_states()[-1]} = {config.trend.get_state_label(config.trend.get_all_states()[-1])}\")\n",
    "print(f\"   vol_0 = {config.volatility.get_state_label(0)}\")\n",
    "print(f\"   vol_{config.volatility.get_all_states()[-1]} = {config.volatility.get_state_label(config.volatility.get_all_states()[-1])}\")\n",
    "\n",
    "print(f\"\\n✅ Regime configuration complete - ready for training\")\n",
    "print(f\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "g0bekobj3be",
   "metadata": {},
   "source": [
    "## 📋 Regime System Information\n",
    "\n",
    "**Key Features of the Integer-Based Regime System:**\n",
    "\n",
    "- **Integer States**: Regimes use integer states (0, 1, 2, ...)\n",
    "- **Descriptive Labels**: Each state has a descriptive name\n",
    "- **Flexible Configuration**: Easily change number of states\n",
    "- **Backwards Compatible**: Existing code continues to work\n",
    "- **Mathematical Operations**: Efficient for calculations\n",
    "\n",
    "**Example Configurations:**\n",
    "- 3×3 = 9 regimes (simple)\n",
    "- 5×3 = 15 regimes (default, balanced)  \n",
    "- 7×5 = 35 regimes (detailed)\n",
    "\n",
    "**State Mapping:**\n",
    "- `trend_0` → strongest bearish trend\n",
    "- `trend_N-1` → strongest bullish trend  \n",
    "- `vol_0` → lowest volatility\n",
    "- `vol_N-1` → highest volatility"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step1",
   "metadata": {},
   "source": [
    "## 1. Optional: Load Universe Data\n",
    "\n",
    "**OPTIONAL**: Load fresh data from US universe file instead of using cached stock_data.pkl\n",
    "\n",
    "To use the US universe data, uncomment and run the cell below. This will load data for up to 5013 stocks from the US universe file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "load_data",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded 2315 stocks\n",
      "✅ Prepared 2298 stocks for training\n",
      "✅ Selected 20 stocks for individual models\n",
      "🎯 Target stock: A\n",
      "\n",
      "📊 Data Summary:\n",
      "   Total symbols loaded: 2315\n",
      "   Symbols with sufficient data: 2298\n",
      "   High-quality stocks: 1924\n",
      "   Individual models: 20\n",
      "   Target stock: A\n",
      "\n",
      "💡 To load US universe data instead:\n",
      "   1. Uncomment the 'OPTIONAL' section above\n",
      "   2. Comment out the 'DEFAULT' section\n",
      "   3. Adjust max_symbols parameter as needed\n",
      "   4. Set update=True to fetch fresh data\n"
     ]
    }
   ],
   "source": [
    "# OPTIONAL: Load fresh data from US universe file\n",
    "# Uncomment the lines below to load data from the US universe_2025-08-05* file\n",
    "# This will load up to 5013 stocks from the universe file\n",
    "\n",
    "# from data.loader import load_universe_data\n",
    "# print(\"🌍 Loading data from US universe file...\")\n",
    "# stock_data = load_universe_data(max_symbols=100, update=False, rate_limit=2.0)  # Limit to 100 for demo\n",
    "# print(f\"✅ Loaded universe data with {len(stock_data['Close'].columns)} stocks\")\n",
    "\n",
    "# DEFAULT: Load existing cached data\n",
    "with open('../cache/stock_data_universe.pkl', 'rb') as f:\n",
    "    stock_data = pickle.load(f)\n",
    "\n",
    "n_stocks = len(stock_data['Close'].columns)\n",
    "print(f\"✅ Loaded {n_stocks} stocks\")\n",
    "\n",
    "# Prepare data for training\n",
    "def prepare_stock_data(stock_data, symbols, min_obs=50):\n",
    "    prepared = {}\n",
    "    for symbol in symbols:\n",
    "        if symbol in stock_data['Close'].columns:\n",
    "            data = pd.DataFrame({\n",
    "                'Open': stock_data['Open'][symbol],\n",
    "                'High': stock_data['High'][symbol],\n",
    "                'Low': stock_data['Low'][symbol],\n",
    "                'Close': stock_data['Close'][symbol],\n",
    "                'Volume': stock_data['Volume'][symbol]\n",
    "            }).dropna()\n",
    "            \n",
    "            if len(data) >= min_obs:\n",
    "                # Add technical indicators for Markov models\n",
    "                close = data['Close']\n",
    "                data['MA'] = close.rolling(20).mean()\n",
    "                bb_std = close.rolling(20).std()\n",
    "                data['BB_Upper'] = data['MA'] + 2 * bb_std\n",
    "                data['BB_Lower'] = data['MA'] - 2 * bb_std\n",
    "                \n",
    "                # Calculate BB_Position (-1 to 1, where 0 is at MA)\n",
    "                data['BB_Position'] = (close - data['MA']) / (data['BB_Upper'] - data['MA'])\n",
    "                data['BB_Position'] = data['BB_Position'].clip(-1, 1)\n",
    "                \n",
    "                # BB_Width for other models\n",
    "                data['BB_Width'] = bb_std / data['MA']\n",
    "                \n",
    "                prepared[symbol] = data.dropna()\n",
    "    \n",
    "    return prepared\n",
    "\n",
    "# Prepare all stocks\n",
    "all_symbols = stock_data['Close'].columns.tolist()\n",
    "all_prepared_data = prepare_stock_data(stock_data, all_symbols)\n",
    "print(f\"✅ Prepared {len(all_prepared_data)} stocks for training\")\n",
    "\n",
    "# Select high-quality subset for individual models\n",
    "completeness = (1 - stock_data['Close'].isnull().sum() / len(stock_data['Close'])) * 100\n",
    "high_quality = completeness[completeness >= 95].index.tolist()\n",
    "individual_stocks = [s for s in high_quality[:20] if s in all_prepared_data]\n",
    "print(f\"✅ Selected {len(individual_stocks)} stocks for individual models\")\n",
    "\n",
    "# Target stock\n",
    "target_stock = 'TSLA' if 'TSLA' in individual_stocks else individual_stocks[0]\n",
    "print(f\"🎯 Target stock: {target_stock}\")\n",
    "\n",
    "print(f\"\\n📊 Data Summary:\")\n",
    "print(f\"   Total symbols loaded: {len(all_symbols)}\")\n",
    "print(f\"   Symbols with sufficient data: {len(all_prepared_data)}\")\n",
    "print(f\"   High-quality stocks: {len(high_quality)}\")\n",
    "print(f\"   Individual models: {len(individual_stocks)}\")\n",
    "print(f\"   Target stock: {target_stock}\")\n",
    "\n",
    "# Show usage instructions\n",
    "print(f\"\\n💡 To load US universe data instead:\")\n",
    "print(f\"   1. Uncomment the 'OPTIONAL' section above\")\n",
    "print(f\"   2. Comment out the 'DEFAULT' section\") \n",
    "print(f\"   3. Adjust max_symbols parameter as needed\")\n",
    "print(f\"   4. Set update=True to fetch fresh data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step2",
   "metadata": {},
   "source": [
    "## 2. Train Global Markov Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "global_markov",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 Training global Markov model on 2298 stocks...\n",
      "   Using integer regime system with 7×5 = 35 regimes\n",
      "Initialized combined Markov model with 35 states:\n",
      "States: ['very_strong_bear_very_low', 'very_strong_bear_low', 'very_strong_bear_medium', 'very_strong_bear_high', 'very_strong_bear_very_high', 'strong_bear_very_low', 'strong_bear_low', 'strong_bear_medium', 'strong_bear_high', 'strong_bear_very_high', 'bear_very_low', 'bear_low', 'bear_medium', 'bear_high', 'bear_very_high', 'sideways_very_low', 'sideways_low', 'sideways_medium', 'sideways_high', 'sideways_very_high', 'bull_very_low', 'bull_low', 'bull_medium', 'bull_high', 'bull_very_high', 'strong_bull_very_low', 'strong_bull_low', 'strong_bull_medium', 'strong_bull_high', 'strong_bull_very_high', 'very_strong_bull_very_low', 'very_strong_bull_low', 'very_strong_bull_medium', 'very_strong_bull_high', 'very_strong_bull_very_high']\n",
      "🔧 Fitting combined Markov model...\n",
      "  📊 Collected 2659467 regime observations from 2298 stocks\n",
      "  📈 Estimated transition matrix from 2659467 observations\n",
      "  📊 SPARSE BUCKET DIAGNOSTIC: 5 least populated buckets:\n",
      "     1. strong_bear_medium: 9692 samples\n",
      "     2. strong_bull_medium: 10277 samples\n",
      "     3. bear_medium: 10319 samples\n",
      "     4. bull_medium: 10463 samples\n",
      "     5. strong_bear_low: 13493 samples\n",
      "✅ Markov model fitting complete!\n",
      "✅ Global Markov model trained successfully\n",
      "   Model type: combined\n",
      "   States: 35\n",
      "   Using centralized regime config: ✅\n",
      "   Top 5 regimes by frequency:\n",
      "     very_strong_bear_very_high: 0.241 (640529 obs)\n",
      "     very_strong_bull_very_high: 0.236 (628237 obs)\n",
      "     very_strong_bull_high: 0.064 (169911 obs)\n",
      "     very_strong_bear_high: 0.056 (149022 obs)\n",
      "     very_strong_bull_very_low: 0.048 (128834 obs)\n"
     ]
    }
   ],
   "source": [
    "from models.unified_markov_model import create_combined_markov_model\n",
    "\n",
    "print(f\"🔄 Training global Markov model on {len(all_prepared_data)} stocks...\")\n",
    "print(f\"   Using integer regime system with {N_TREND_STATES}×{N_VOL_STATES} = {N_TREND_STATES * N_VOL_STATES} regimes\")\n",
    "\n",
    "# Create unified Markov model that uses centralized regime configuration\n",
    "global_markov = create_combined_markov_model()\n",
    "\n",
    "# Fit the model on all prepared data\n",
    "global_markov.fit(all_prepared_data)\n",
    "\n",
    "# Show model summary\n",
    "if global_markov.fitted:\n",
    "    summary = global_markov.get_model_summary()\n",
    "    print(f\"✅ Global Markov model trained successfully\")\n",
    "    print(f\"   Model type: {summary['model_type']}\")\n",
    "    print(f\"   States: {summary['n_states']}\")\n",
    "    print(f\"   Using centralized regime config: ✅\")\n",
    "    \n",
    "    # Show some state statistics\n",
    "    state_stats = summary['state_statistics']\n",
    "    top_states = sorted(state_stats.items(), key=lambda x: x[1]['frequency'], reverse=True)[:5]\n",
    "    print(f\"   Top 5 regimes by frequency:\")\n",
    "    for state, stats in top_states:\n",
    "        print(f\"     {state}: {stats['frequency']:.3f} ({stats['count']} obs)\")\n",
    "else:\n",
    "    print(f\"❌ Global Markov model training failed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step3",
   "metadata": {},
   "source": [
    "## 3. Global Model Training Only\n",
    "\n",
    "**Removed per-stock training - all models are now global only!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "individual_markov",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 Individual Markov model training has been removed from the pipeline\n",
      "   All predictions now use the global Markov model trained on all stocks\n",
      "   This provides more robust and deterministic results\n",
      "✅ Global-only training approach adopted\n",
      "   Using unified Markov model with 35 states\n",
      "   Trained on 2298 stocks globally\n"
     ]
    }
   ],
   "source": [
    "# REMOVED: Individual stock Markov training - now using global models only!\n",
    "print(\"🔄 Individual Markov model training has been removed from the pipeline\")\n",
    "print(\"   All predictions now use the global Markov model trained on all stocks\")\n",
    "print(\"   This provides more robust and deterministic results\")\n",
    "\n",
    "individual_markov = {}  # Keep for compatibility\n",
    "successful_models = 0\n",
    "\n",
    "print(f\"✅ Global-only training approach adopted\")\n",
    "print(f\"   Using unified Markov model with {global_markov.n_states} states\")\n",
    "print(f\"   Trained on {len(all_prepared_data)} stocks globally\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step4",
   "metadata": {},
   "source": [
    "## 4. Train Close Price KDE Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "close_kde",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 Training global KDE models on ALL data using integer regime system...\n",
      "   Using 7 trend states × 5 vol states = 35 total regimes\n",
      "🚀 Training All Global Models on All Data\n",
      "================================================================================\n",
      "🌍 Training Global Close Price KDE Models\n",
      "============================================================\n",
      "  📊 Processed 50 stocks...\n",
      "  📊 Processed 100 stocks...\n",
      "  📊 Processed 150 stocks...\n",
      "  📊 Processed 200 stocks...\n",
      "  📊 Processed 250 stocks...\n",
      "  📊 Processed 300 stocks...\n",
      "  📊 Processed 350 stocks...\n",
      "  📊 Processed 400 stocks...\n",
      "  📊 Processed 450 stocks...\n",
      "  📊 Processed 500 stocks...\n",
      "  📊 Processed 550 stocks...\n",
      "  📊 Processed 600 stocks...\n",
      "  📊 Processed 650 stocks...\n",
      "  📊 Processed 700 stocks...\n",
      "  📊 Processed 750 stocks...\n",
      "  📊 Processed 800 stocks...\n",
      "  📊 Processed 850 stocks...\n",
      "  📊 Processed 900 stocks...\n",
      "  📊 Processed 950 stocks...\n",
      "  📊 Processed 1000 stocks...\n",
      "  📊 Processed 1050 stocks...\n",
      "  📊 Processed 1100 stocks...\n",
      "  📊 Processed 1150 stocks...\n",
      "  📊 Processed 1200 stocks...\n",
      "  📊 Processed 1250 stocks...\n",
      "  📊 Processed 1300 stocks...\n",
      "  📊 Processed 1350 stocks...\n",
      "  📊 Processed 1400 stocks...\n",
      "  📊 Processed 1450 stocks...\n",
      "  📊 Processed 1500 stocks...\n",
      "  📊 Processed 1550 stocks...\n",
      "  📊 Processed 1600 stocks...\n",
      "  📊 Processed 1650 stocks...\n",
      "  📊 Processed 1700 stocks...\n",
      "  📊 Processed 1750 stocks...\n",
      "  📊 Processed 1800 stocks...\n",
      "  📊 Processed 1850 stocks...\n",
      "  📊 Processed 1900 stocks...\n",
      "  📊 Processed 1950 stocks...\n",
      "  📊 Processed 2000 stocks...\n",
      "  📊 Processed 2050 stocks...\n",
      "  📊 Processed 2100 stocks...\n",
      "  📊 Processed 2150 stocks...\n",
      "  📊 Processed 2200 stocks...\n",
      "  📊 Processed 2250 stocks...\n",
      "  📊 Combined data: 2657169 close price observations from 2298 stocks\n",
      "🎯 Training regime-specific Close Price KDE models...\n",
      "  📊 Found 35 regimes:\n",
      "    very_strong_bear_very_high: 640529 samples ✅ KDE trained\n",
      "    very_strong_bull_very_high: 628237 samples ✅ KDE trained\n",
      "    very_strong_bull_high: 169911 samples ✅ KDE trained\n",
      "    very_strong_bear_high: 149022 samples ✅ KDE trained\n",
      "    very_strong_bull_very_low: 128834 samples ✅ KDE trained\n",
      "    very_strong_bull_low: 123018 samples ✅ KDE trained\n",
      "    very_strong_bull_medium: 98786 samples ✅ KDE trained\n",
      "    very_strong_bear_low: 91855 samples ✅ KDE trained\n",
      "    very_strong_bear_medium: 84305 samples ✅ KDE trained\n",
      "    very_strong_bear_very_low: 73664 samples ✅ KDE trained\n",
      "    sideways_very_high: 32566 samples ✅ KDE trained\n",
      "    bear_very_high: 32529 samples ✅ KDE trained\n",
      "    strong_bear_very_high: 32501 samples ✅ KDE trained\n",
      "    strong_bull_very_high: 31830 samples ✅ KDE trained\n",
      "    bull_very_high: 31817 samples ✅ KDE trained\n",
      "    sideways_very_low: 25078 samples ✅ KDE trained\n",
      "    bull_very_low: 23665 samples ✅ KDE trained\n",
      "    sideways_medium: 19441 samples ✅ KDE trained\n",
      "    strong_bull_very_low: 19394 samples ✅ KDE trained\n",
      "    bear_very_low: 18496 samples ✅ KDE trained\n",
      "    strong_bear_very_low: 16059 samples ✅ KDE trained\n",
      "    bear_high: 14928 samples ✅ KDE trained\n",
      "    bull_high: 14916 samples ✅ KDE trained\n",
      "    sideways_high: 14909 samples ✅ KDE trained\n",
      "    strong_bull_high: 14803 samples ✅ KDE trained\n",
      "    bull_low: 14609 samples ✅ KDE trained\n",
      "    sideways_low: 14545 samples ✅ KDE trained\n",
      "    strong_bear_high: 14470 samples ✅ KDE trained\n",
      "    strong_bull_low: 14292 samples ✅ KDE trained\n",
      "    bear_low: 13916 samples ✅ KDE trained\n",
      "    strong_bear_low: 13493 samples ✅ KDE trained\n",
      "    bull_medium: 10463 samples ✅ KDE trained\n",
      "    bear_medium: 10319 samples ✅ KDE trained\n",
      "    strong_bull_medium: 10277 samples ✅ KDE trained\n",
      "    strong_bear_medium: 9692 samples ✅ KDE trained\n",
      "  ✅ Successfully trained 35 Close Price KDE models\n",
      "  📊 Total regimes with KDEs: 35\n",
      "✅ Global Close Price KDE training complete!\n",
      "✅ Global Close Price KDE trained\n",
      "🌍 Training Global Open Price KDE Models\n",
      "============================================================\n",
      "  📊 Processed 50 stocks...\n",
      "  📊 Processed 100 stocks...\n",
      "  📊 Processed 150 stocks...\n",
      "  📊 Processed 200 stocks...\n",
      "  📊 Processed 250 stocks...\n",
      "  📊 Processed 300 stocks...\n",
      "  📊 Processed 350 stocks...\n",
      "  📊 Processed 400 stocks...\n",
      "  📊 Processed 450 stocks...\n",
      "  📊 Processed 500 stocks...\n",
      "  📊 Processed 550 stocks...\n",
      "  📊 Processed 600 stocks...\n",
      "  📊 Processed 650 stocks...\n",
      "  📊 Processed 700 stocks...\n",
      "  📊 Processed 750 stocks...\n",
      "  📊 Processed 800 stocks...\n",
      "  📊 Processed 850 stocks...\n",
      "  📊 Processed 900 stocks...\n",
      "  📊 Processed 950 stocks...\n",
      "  📊 Processed 1000 stocks...\n",
      "  📊 Processed 1050 stocks...\n",
      "  📊 Processed 1100 stocks...\n",
      "  📊 Processed 1150 stocks...\n",
      "  📊 Processed 1200 stocks...\n",
      "  📊 Processed 1250 stocks...\n",
      "  📊 Processed 1300 stocks...\n",
      "  📊 Processed 1350 stocks...\n",
      "  📊 Processed 1400 stocks...\n",
      "  📊 Processed 1450 stocks...\n",
      "  📊 Processed 1500 stocks...\n",
      "  📊 Processed 1550 stocks...\n",
      "  📊 Processed 1600 stocks...\n",
      "  📊 Processed 1650 stocks...\n",
      "  📊 Processed 1700 stocks...\n",
      "  📊 Processed 1750 stocks...\n",
      "  📊 Processed 1800 stocks...\n",
      "  📊 Processed 1850 stocks...\n",
      "  📊 Processed 1900 stocks...\n",
      "  📊 Processed 1950 stocks...\n",
      "  📊 Processed 2000 stocks...\n",
      "  📊 Processed 2050 stocks...\n",
      "  📊 Processed 2100 stocks...\n",
      "  📊 Processed 2150 stocks...\n",
      "  📊 Processed 2200 stocks...\n",
      "  📊 Processed 2250 stocks...\n",
      "  📊 Combined data: 2657169 gap observations from 2298 stocks\n",
      "🎯 Training regime-specific Open Price KDE models...\n",
      "  📊 Found 35 regimes:\n",
      "    very_strong_bear_very_high: 642309 samples ✅ KDE trained\n",
      "    very_strong_bull_very_high: 625754 samples ✅ KDE trained\n",
      "    very_strong_bull_high: 169712 samples ✅ KDE trained\n",
      "    very_strong_bear_high: 148981 samples ✅ KDE trained\n",
      "    very_strong_bull_very_low: 130442 samples ✅ KDE trained\n",
      "    very_strong_bull_low: 123682 samples ✅ KDE trained\n",
      "    very_strong_bull_medium: 98389 samples ✅ KDE trained\n",
      "    very_strong_bear_low: 91267 samples ✅ KDE trained\n",
      "    very_strong_bear_medium: 82987 samples ✅ KDE trained\n",
      "    very_strong_bear_very_low: 72768 samples ✅ KDE trained\n",
      "    sideways_very_high: 32668 samples ✅ KDE trained\n",
      "    bear_very_high: 32656 samples ✅ KDE trained\n",
      "    strong_bear_very_high: 32628 samples ✅ KDE trained\n",
      "    bull_very_high: 32004 samples ✅ KDE trained\n",
      "    strong_bull_very_high: 31990 samples ✅ KDE trained\n",
      "    sideways_very_low: 24944 samples ✅ KDE trained\n",
      "    bull_very_low: 23597 samples ✅ KDE trained\n",
      "    sideways_medium: 21697 samples ✅ KDE trained\n",
      "    strong_bull_very_low: 19274 samples ✅ KDE trained\n",
      "    bear_very_low: 18302 samples ✅ KDE trained\n",
      "    strong_bear_very_low: 15863 samples ✅ KDE trained\n",
      "    bear_high: 14999 samples ✅ KDE trained\n",
      "    sideways_high: 14990 samples ✅ KDE trained\n",
      "    bull_high: 14871 samples ✅ KDE trained\n",
      "    strong_bull_high: 14861 samples ✅ KDE trained\n",
      "    strong_bear_high: 14545 samples ✅ KDE trained\n",
      "    bull_low: 14523 samples ✅ KDE trained\n",
      "    sideways_low: 14449 samples ✅ KDE trained\n",
      "    strong_bull_low: 14266 samples ✅ KDE trained\n",
      "    bear_low: 14045 samples ✅ KDE trained\n",
      "    strong_bear_low: 13496 samples ✅ KDE trained\n",
      "    bull_medium: 10390 samples ✅ KDE trained\n",
      "    strong_bull_medium: 10133 samples ✅ KDE trained\n",
      "    bear_medium: 10101 samples ✅ KDE trained\n",
      "    strong_bear_medium: 9586 samples ✅ KDE trained\n",
      "  ✅ Successfully trained 35 Open Price KDE models\n",
      "  📊 Total regimes with KDEs: 35\n",
      "✅ Global Open Price KDE training complete!\n",
      "✅ Global Open Price KDE trained\n",
      "🌍 Training Global High-Low Copula Models\n",
      "============================================================\n",
      "  📊 Processed 50 stocks...\n",
      "  📊 Processed 100 stocks...\n",
      "  📊 Processed 150 stocks...\n",
      "  📊 Processed 200 stocks...\n",
      "  📊 Processed 250 stocks...\n",
      "  📊 Processed 300 stocks...\n",
      "  📊 Processed 350 stocks...\n",
      "  📊 Processed 400 stocks...\n",
      "  📊 Processed 450 stocks...\n",
      "  📊 Processed 500 stocks...\n",
      "  📊 Processed 550 stocks...\n",
      "  📊 Processed 600 stocks...\n",
      "  📊 Processed 650 stocks...\n",
      "  📊 Processed 700 stocks...\n",
      "  📊 Processed 750 stocks...\n",
      "  📊 Processed 800 stocks...\n",
      "  📊 Processed 850 stocks...\n",
      "  📊 Processed 900 stocks...\n",
      "  📊 Processed 950 stocks...\n",
      "  📊 Processed 1000 stocks...\n",
      "  📊 Processed 1050 stocks...\n",
      "  📊 Processed 1100 stocks...\n",
      "  📊 Processed 1150 stocks...\n",
      "  📊 Processed 1200 stocks...\n",
      "  📊 Processed 1250 stocks...\n",
      "  📊 Processed 1300 stocks...\n",
      "  📊 Processed 1350 stocks...\n",
      "  📊 Processed 1400 stocks...\n",
      "  📊 Processed 1450 stocks...\n",
      "  📊 Processed 1500 stocks...\n",
      "  📊 Processed 1550 stocks...\n",
      "  📊 Processed 1600 stocks...\n",
      "  📊 Processed 1650 stocks...\n",
      "  📊 Processed 1700 stocks...\n",
      "  📊 Processed 1750 stocks...\n",
      "  📊 Processed 1800 stocks...\n",
      "  📊 Processed 1850 stocks...\n",
      "  📊 Processed 1900 stocks...\n",
      "  📊 Processed 1950 stocks...\n",
      "  📊 Processed 2000 stocks...\n",
      "  📊 Processed 2050 stocks...\n",
      "  📊 Processed 2100 stocks...\n",
      "  📊 Processed 2150 stocks...\n",
      "  📊 Processed 2200 stocks...\n",
      "  📊 Processed 2250 stocks...\n",
      "  📊 Combined data: 2659467 high-low observations from 2298 stocks\n",
      "🎯 Training regime-specific Copula models...\n",
      "  📊 Found 35 regimes:\n",
      "    very_strong_bear_very_high: 640529 samples ✅ Copula trained\n",
      "    very_strong_bull_very_high: 628237 samples ✅ Copula trained\n",
      "    very_strong_bull_high: 169911 samples ✅ Copula trained\n",
      "    very_strong_bear_high: 149022 samples ✅ Copula trained\n",
      "    very_strong_bull_very_low: 128834 samples ✅ Copula trained\n",
      "    very_strong_bull_low: 123018 samples ✅ Copula trained\n",
      "    very_strong_bull_medium: 98786 samples ✅ Copula trained\n",
      "    very_strong_bear_low: 91855 samples ✅ Copula trained\n",
      "    very_strong_bear_medium: 84305 samples ✅ Copula trained\n",
      "    very_strong_bear_very_low: 73664 samples ✅ Copula trained\n",
      "    sideways_very_high: 32566 samples ✅ Copula trained\n",
      "    bear_very_high: 32529 samples ✅ Copula trained\n",
      "    strong_bear_very_high: 32501 samples ✅ Copula trained\n",
      "    strong_bull_very_high: 31830 samples ✅ Copula trained\n",
      "    bull_very_high: 31817 samples ✅ Copula trained\n",
      "    sideways_very_low: 25078 samples ✅ Copula trained\n",
      "    bull_very_low: 23665 samples ✅ Copula trained\n",
      "    sideways_medium: 21739 samples ✅ Copula trained\n",
      "    strong_bull_very_low: 19394 samples ✅ Copula trained\n",
      "    bear_very_low: 18496 samples ✅ Copula trained\n",
      "    strong_bear_very_low: 16059 samples ✅ Copula trained\n",
      "    bear_high: 14928 samples ✅ Copula trained\n",
      "    bull_high: 14916 samples ✅ Copula trained\n",
      "    sideways_high: 14909 samples ✅ Copula trained\n",
      "    strong_bull_high: 14803 samples ✅ Copula trained\n",
      "    bull_low: 14609 samples ✅ Copula trained\n",
      "    sideways_low: 14545 samples ✅ Copula trained\n",
      "    strong_bear_high: 14470 samples ✅ Copula trained\n",
      "    strong_bull_low: 14292 samples ✅ Copula trained\n",
      "    bear_low: 13916 samples ✅ Copula trained\n",
      "    strong_bear_low: 13493 samples ✅ Copula trained\n",
      "    bull_medium: 10463 samples ✅ Copula trained\n",
      "    bear_medium: 10319 samples ✅ Copula trained\n",
      "    strong_bull_medium: 10277 samples ✅ Copula trained\n",
      "    strong_bear_medium: 9692 samples ✅ Copula trained\n",
      "  ✅ Successfully trained 35 Copula models\n",
      "  📊 Total regimes with Copulas: 35\n",
      "✅ Global High-Low Copula training complete!\n",
      "✅ Global High-Low Copula trained\n",
      "\n",
      "🎯 Global Model Training Results: 3/3 models trained successfully\n",
      "✅ Global KDE models trained on all 2298 stocks\n",
      "   Close Price KDE: ✅\n",
      "   Open Price KDE: ✅\n",
      "   High-Low Copula: ✅\n",
      "\n",
      "📊 Close Price KDE Statistics (Integer Regime System):\n",
      "   KDE Models: 35 regimes\n",
      "   Total Regimes: 35 identified\n",
      "   Top Regimes: very_strong_bear_very_high, very_strong_bull_very_high, very_strong_bull_high\n",
      "\n",
      "🔄 Regime State Analysis:\n",
      "   'very_strong_bear_very_high' = trend_2 (sideways) + vol_1 (medium)\n",
      "   'very_strong_bull_very_high' = trend_2 (sideways) + vol_1 (medium)\n",
      "\n",
      "📊 Open Price KDE Statistics:\n",
      "   KDE Models: 35 regimes\n",
      "\n",
      "📊 High-Low Copula Statistics:\n",
      "   Copula Models: 35 regimes\n",
      "\n",
      "🎛️ Using Integer Regime Configuration:\n",
      "   Trend states: [0, 1, 2, 3, 4] → ['strong_bear', 'bear', 'sideways', 'bull', 'strong_bull']\n",
      "   Vol states: [0, 1, 2] → ['low', 'medium', 'high']\n"
     ]
    }
   ],
   "source": [
    "from models.global_kde_models import train_global_models\n",
    "\n",
    "print(f\"🔄 Training global KDE models on ALL data using integer regime system...\")\n",
    "print(f\"   Using {N_TREND_STATES} trend states × {N_VOL_STATES} vol states = {N_TREND_STATES * N_VOL_STATES} total regimes\")\n",
    "\n",
    "# Train all global models on complete dataset using new integer regime system\n",
    "global_models = train_global_models(all_prepared_data, min_samples=50)\n",
    "\n",
    "# Extract individual models for compatibility\n",
    "global_close_kde = global_models['close_kde']\n",
    "global_open_kde = global_models['open_kde'] \n",
    "global_hl_copula = global_models['hl_copula']\n",
    "\n",
    "print(f\"✅ Global KDE models trained on all {len(all_prepared_data)} stocks\")\n",
    "print(f\"   Close Price KDE: {'✅' if global_close_kde else '❌'}\")\n",
    "print(f\"   Open Price KDE: {'✅' if global_open_kde else '❌'}\")\n",
    "print(f\"   High-Low Copula: {'✅' if global_hl_copula else '❌'}\")\n",
    "\n",
    "# Show regime statistics for first successful model\n",
    "if global_close_kde and global_close_kde.fitted:\n",
    "    regime_count = len(global_close_kde.kde_models)\n",
    "    total_regimes = len(global_close_kde.regime_stats)\n",
    "    print(f\"\\n📊 Close Price KDE Statistics (Integer Regime System):\")\n",
    "    print(f\"   KDE Models: {regime_count} regimes\")\n",
    "    print(f\"   Total Regimes: {total_regimes} identified\")\n",
    "    \n",
    "    if regime_count > 0:\n",
    "        top_regimes = list(global_close_kde.kde_models.keys())[:3]\n",
    "        print(f\"   Top Regimes: {', '.join(top_regimes)}\")\n",
    "        \n",
    "        # Show state-label conversion for regimes\n",
    "        print(f\"\\n🔄 Regime State Analysis:\")\n",
    "        from models.regime_classifier import REGIME_CLASSIFIER\n",
    "        for regime in top_regimes[:2]:  # Show first 2 regimes\n",
    "            try:\n",
    "                trend_state, vol_state = REGIME_CONFIG.label_to_state(regime)\n",
    "                trend_label = REGIME_CONFIG.trend.get_state_label(trend_state)\n",
    "                vol_label = REGIME_CONFIG.volatility.get_state_label(vol_state)\n",
    "                print(f\"   '{regime}' = trend_{trend_state} ({trend_label}) + vol_{vol_state} ({vol_label})\")\n",
    "            except:\n",
    "                print(f\"   '{regime}' = descriptive label\")\n",
    "\n",
    "if global_open_kde and global_open_kde.fitted:\n",
    "    regime_count = len(global_open_kde.kde_models)\n",
    "    print(f\"\\n📊 Open Price KDE Statistics:\")\n",
    "    print(f\"   KDE Models: {regime_count} regimes\")\n",
    "\n",
    "if global_hl_copula and global_hl_copula.fitted:\n",
    "    regime_count = len(global_hl_copula.copula_models)\n",
    "    print(f\"\\n📊 High-Low Copula Statistics:\")\n",
    "    print(f\"   Copula Models: {regime_count} regimes\")\n",
    "\n",
    "# Show regime configuration being used\n",
    "print(f\"\\n🎛️ Using Integer Regime Configuration:\")\n",
    "print(f\"   Trend states: {REGIME_CONFIG.trend.get_all_states()} → {REGIME_CONFIG.trend.get_all_labels()}\")\n",
    "print(f\"   Vol states: {REGIME_CONFIG.volatility.get_all_states()} → {REGIME_CONFIG.volatility.get_all_labels()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step5",
   "metadata": {},
   "source": [
    "## 5. Train Open Price Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "open_models",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Open price models already trained globally\n",
      "   Global Open KDE covers all 2298 stocks\n",
      "   Regime-resolved by trend and volatility\n"
     ]
    }
   ],
   "source": [
    "# Open price models are now trained globally in previous step\n",
    "print(f\"✅ Open price models already trained globally\")\n",
    "print(f\"   Global Open KDE covers all {len(all_prepared_data)} stocks\")\n",
    "print(f\"   Regime-resolved by trend and volatility\")\n",
    "\n",
    "# For compatibility, create reference\n",
    "open_forecaster = global_open_kde"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step6",
   "metadata": {},
   "source": [
    "## 6. Train High/Low Copula Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "copula_models",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ High/Low copula models already trained globally\n",
      "   Global High-Low Copula covers all 2298 stocks\n",
      "   Regime-resolved by trend and volatility\n"
     ]
    }
   ],
   "source": [
    "# High/Low copula models are now trained globally in previous step\n",
    "print(f\"✅ High/Low copula models already trained globally\")\n",
    "print(f\"   Global High-Low Copula covers all {len(all_prepared_data)} stocks\")\n",
    "print(f\"   Regime-resolved by trend and volatility\")\n",
    "\n",
    "# For compatibility, create reference\n",
    "hl_forecaster = global_hl_copula"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step7",
   "metadata": {},
   "source": [
    "## 7. Train Individual ARIMA-GARCH Models\n",
    "\n",
    "**Enhanced to use auto_arima with GARCH(1,1) - individual stock training required for time series models!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "garch_models",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 Training individual ARIMA-GARCH models...\n",
      "   Note: ARIMA-GARCH models MUST be trained per stock (time series specific)\n",
      "🚀 Training Combined ARIMA-GARCH Model\n",
      "==================================================\n",
      "🔄 Fitting ARIMA model for 20-day moving average...\n",
      "✅ ARIMA model fitted: (1, 1, 0)\n",
      "🔄 Fitting GARCH model for Bollinger Band volatility...\n",
      "✅ GARCH model fitted for BB volatility\n",
      "✅ Combined ARIMA-GARCH model fitted\n",
      "✅ A: ARIMA-ARIMA + GARCH-GARCH\n",
      "🚀 Training Combined ARIMA-GARCH Model\n",
      "==================================================\n",
      "🔄 Fitting ARIMA model for 20-day moving average...\n",
      "✅ ARIMA model fitted: (0, 2, 0)\n",
      "🔄 Fitting GARCH model for Bollinger Band volatility...\n",
      "✅ GARCH model fitted for BB volatility\n",
      "✅ Combined ARIMA-GARCH model fitted\n",
      "✅ AA: ARIMA-ARIMA + GARCH-GARCH\n",
      "🚀 Training Combined ARIMA-GARCH Model\n",
      "==================================================\n",
      "🔄 Fitting ARIMA model for 20-day moving average...\n",
      "✅ ARIMA model fitted: (2, 1, 1)\n",
      "🔄 Fitting GARCH model for Bollinger Band volatility...\n",
      "✅ GARCH model fitted for BB volatility\n",
      "✅ Combined ARIMA-GARCH model fitted\n",
      "✅ AAL: ARIMA-ARIMA + GARCH-GARCH\n",
      "🚀 Training Combined ARIMA-GARCH Model\n",
      "==================================================\n",
      "🔄 Fitting ARIMA model for 20-day moving average...\n",
      "✅ ARIMA model fitted: (1, 1, 0)\n",
      "🔄 Fitting GARCH model for Bollinger Band volatility...\n",
      "✅ GARCH model fitted for BB volatility\n",
      "✅ Combined ARIMA-GARCH model fitted\n",
      "✅ AAOI: ARIMA-ARIMA + GARCH-GARCH\n",
      "🚀 Training Combined ARIMA-GARCH Model\n",
      "==================================================\n",
      "🔄 Fitting ARIMA model for 20-day moving average...\n",
      "✅ ARIMA model fitted: (2, 1, 2)\n",
      "🔄 Fitting GARCH model for Bollinger Band volatility...\n",
      "✅ GARCH model fitted for BB volatility\n",
      "✅ Combined ARIMA-GARCH model fitted\n",
      "✅ AAON: ARIMA-ARIMA + GARCH-GARCH\n",
      "🚀 Training Combined ARIMA-GARCH Model\n",
      "==================================================\n",
      "🔄 Fitting ARIMA model for 20-day moving average...\n",
      "✅ ARIMA model fitted: (0, 2, 1)\n",
      "🔄 Fitting GARCH model for Bollinger Band volatility...\n",
      "✅ GARCH model fitted for BB volatility\n",
      "✅ Combined ARIMA-GARCH model fitted\n",
      "✅ AAP: ARIMA-ARIMA + GARCH-GARCH\n",
      "🚀 Training Combined ARIMA-GARCH Model\n",
      "==================================================\n",
      "🔄 Fitting ARIMA model for 20-day moving average...\n",
      "✅ ARIMA model fitted: (2, 1, 0)\n",
      "🔄 Fitting GARCH model for Bollinger Band volatility...\n",
      "✅ GARCH model fitted for BB volatility\n",
      "✅ Combined ARIMA-GARCH model fitted\n",
      "✅ AAPL: ARIMA-ARIMA + GARCH-GARCH\n",
      "🚀 Training Combined ARIMA-GARCH Model\n",
      "==================================================\n",
      "🔄 Fitting ARIMA model for 20-day moving average...\n",
      "✅ ARIMA model fitted: (2, 1, 1)\n",
      "🔄 Fitting GARCH model for Bollinger Band volatility...\n",
      "✅ GARCH model fitted for BB volatility\n",
      "✅ Combined ARIMA-GARCH model fitted\n",
      "✅ ABBV: ARIMA-ARIMA + GARCH-GARCH\n",
      "🚀 Training Combined ARIMA-GARCH Model\n",
      "==================================================\n",
      "🔄 Fitting ARIMA model for 20-day moving average...\n",
      "✅ ARIMA model fitted: (1, 1, 0)\n",
      "🔄 Fitting GARCH model for Bollinger Band volatility...\n",
      "✅ GARCH model fitted for BB volatility\n",
      "✅ Combined ARIMA-GARCH model fitted\n",
      "✅ ABCB: ARIMA-ARIMA + GARCH-GARCH\n",
      "🚀 Training Combined ARIMA-GARCH Model\n",
      "==================================================\n",
      "❌ ARIMA fitting failed: Need at least 50 observations for ARIMA, got 47\n",
      "❌ GARCH fitting failed: Need at least 50 observations for GARCH, got 47\n",
      "❌ Both ARIMA and GARCH fitting failed\n",
      "✅ ABCCF: ARIMA-Unknown + GARCH-Unknown\n",
      "🚀 Training Combined ARIMA-GARCH Model\n",
      "==================================================\n",
      "🔄 Fitting ARIMA model for 20-day moving average...\n",
      "✅ ARIMA model fitted: (1, 2, 1)\n",
      "🔄 Fitting GARCH model for Bollinger Band volatility...\n",
      "✅ GARCH model fitted for BB volatility\n",
      "✅ Combined ARIMA-GARCH model fitted\n",
      "✅ ABEO: ARIMA-ARIMA + GARCH-GARCH\n",
      "🚀 Training Combined ARIMA-GARCH Model\n",
      "==================================================\n",
      "🔄 Fitting ARIMA model for 20-day moving average...\n",
      "✅ ARIMA model fitted: (1, 1, 0)\n",
      "🔄 Fitting GARCH model for Bollinger Band volatility...\n",
      "✅ GARCH model fitted for BB volatility\n",
      "✅ Combined ARIMA-GARCH model fitted\n",
      "✅ ABG: ARIMA-ARIMA + GARCH-GARCH\n",
      "🚀 Training Combined ARIMA-GARCH Model\n",
      "==================================================\n",
      "🔄 Fitting ARIMA model for 20-day moving average...\n",
      "✅ ARIMA model fitted: (3, 1, 0)\n",
      "🔄 Fitting GARCH model for Bollinger Band volatility...\n",
      "✅ GARCH model fitted for BB volatility\n",
      "✅ Combined ARIMA-GARCH model fitted\n",
      "✅ ABL: ARIMA-ARIMA + GARCH-GARCH\n",
      "🚀 Training Combined ARIMA-GARCH Model\n",
      "==================================================\n",
      "🔄 Fitting ARIMA model for 20-day moving average...\n",
      "✅ ARIMA model fitted: (1, 1, 0)\n",
      "🔄 Fitting GARCH model for Bollinger Band volatility...\n",
      "✅ GARCH model fitted for BB volatility\n",
      "✅ Combined ARIMA-GARCH model fitted\n",
      "✅ ABM: ARIMA-ARIMA + GARCH-GARCH\n",
      "🚀 Training Combined ARIMA-GARCH Model\n",
      "==================================================\n",
      "🔄 Fitting ARIMA model for 20-day moving average...\n",
      "✅ ARIMA model fitted: (1, 1, 0)\n",
      "🔄 Fitting GARCH model for Bollinger Band volatility...\n",
      "✅ GARCH model fitted for BB volatility\n",
      "✅ Combined ARIMA-GARCH model fitted\n",
      "✅ ABT: ARIMA-ARIMA + GARCH-GARCH\n",
      "🚀 Training Combined ARIMA-GARCH Model\n",
      "==================================================\n",
      "🔄 Fitting ARIMA model for 20-day moving average...\n",
      "✅ ARIMA model fitted: (2, 1, 1)\n",
      "🔄 Fitting GARCH model for Bollinger Band volatility...\n",
      "✅ GARCH model fitted for BB volatility\n",
      "✅ Combined ARIMA-GARCH model fitted\n",
      "✅ ACA: ARIMA-ARIMA + GARCH-GARCH\n",
      "🚀 Training Combined ARIMA-GARCH Model\n",
      "==================================================\n",
      "🔄 Fitting ARIMA model for 20-day moving average...\n",
      "✅ ARIMA model fitted: (1, 1, 0)\n",
      "🔄 Fitting GARCH model for Bollinger Band volatility...\n",
      "✅ GARCH model fitted for BB volatility\n",
      "✅ Combined ARIMA-GARCH model fitted\n",
      "✅ ACAD: ARIMA-ARIMA + GARCH-GARCH\n",
      "🚀 Training Combined ARIMA-GARCH Model\n",
      "==================================================\n",
      "🔄 Fitting ARIMA model for 20-day moving average...\n",
      "✅ ARIMA model fitted: (1, 1, 0)\n",
      "🔄 Fitting GARCH model for Bollinger Band volatility...\n",
      "✅ GARCH model fitted for BB volatility\n",
      "✅ Combined ARIMA-GARCH model fitted\n",
      "✅ ACEL: ARIMA-ARIMA + GARCH-GARCH\n",
      "🚀 Training Combined ARIMA-GARCH Model\n",
      "==================================================\n",
      "🔄 Fitting ARIMA model for 20-day moving average...\n",
      "✅ ARIMA model fitted: (1, 1, 0)\n",
      "🔄 Fitting GARCH model for Bollinger Band volatility...\n",
      "✅ GARCH model fitted for BB volatility\n",
      "✅ Combined ARIMA-GARCH model fitted\n",
      "✅ ACGL: ARIMA-ARIMA + GARCH-GARCH\n",
      "🚀 Training Combined ARIMA-GARCH Model\n",
      "==================================================\n",
      "🔄 Fitting ARIMA model for 20-day moving average...\n",
      "✅ ARIMA model fitted: (0, 2, 0)\n",
      "🔄 Fitting GARCH model for Bollinger Band volatility...\n",
      "✅ GARCH model fitted for BB volatility\n",
      "✅ Combined ARIMA-GARCH model fitted\n",
      "✅ ACHC: ARIMA-ARIMA + GARCH-GARCH\n",
      "✅ ARIMA-GARCH models trained: 19/20\n",
      "\n",
      "📊 Model Summary for A:\n",
      "   ARIMA Status: fitted\n",
      "   GARCH Status: fitted\n",
      "   ARIMA Order: (1, 1, 0)\n",
      "   Current MA: $117.46\n",
      "   Current BB Width: 0.0307\n",
      "\n",
      "🎯 ARIMA-GARCH Training Summary:\n",
      "   Individual training: ✅ REQUIRED (time series models)\n",
      "   Uses auto_arima for optimal order selection\n",
      "   Uses GARCH(1,1) for volatility modeling\n",
      "   Trained on: 20-day MA and Bollinger Band width\n"
     ]
    }
   ],
   "source": [
    "from models.arima_garch_models import CombinedARIMAGARCHModel\n",
    "\n",
    "print(f\"🔄 Training individual ARIMA-GARCH models...\")\n",
    "print(f\"   Note: ARIMA-GARCH models MUST be trained per stock (time series specific)\")\n",
    "\n",
    "arima_garch_models = {}\n",
    "\n",
    "for symbol in individual_stocks:\n",
    "    try:\n",
    "        close_prices = all_prepared_data[symbol]['Close']\n",
    "        \n",
    "        # Fit combined ARIMA (for MA) + GARCH (for BB) model\n",
    "        model = CombinedARIMAGARCHModel(ma_window=20, bb_std=2.0)\n",
    "        model.fit(close_prices)\n",
    "        arima_garch_models[symbol] = model\n",
    "        \n",
    "        # Print model summary\n",
    "        summary = model.get_model_summary()\n",
    "        arima_type = summary['arima_summary'].get('model_type', 'Unknown')\n",
    "        garch_type = summary['garch_summary'].get('model_type', 'Unknown')\n",
    "        print(f\"✅ {symbol}: ARIMA-{arima_type} + GARCH-{garch_type}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ {symbol} ARIMA-GARCH failed: {str(e)[:50]}\")\n",
    "        arima_garch_models[symbol] = None\n",
    "\n",
    "successful_models = sum(1 for m in arima_garch_models.values() if m is not None and m.fitted)\n",
    "print(f\"✅ ARIMA-GARCH models trained: {successful_models}/{len(individual_stocks)}\")\n",
    "\n",
    "# Show detailed summary for first model\n",
    "if individual_stocks and individual_stocks[0] in arima_garch_models:\n",
    "    first_model = arima_garch_models[individual_stocks[0]]\n",
    "    if first_model and first_model.fitted:\n",
    "        print(f\"\\n📊 Model Summary for {individual_stocks[0]}:\")\n",
    "        summary = first_model.get_model_summary()\n",
    "        print(f\"   ARIMA Status: {summary['arima_summary']['status']}\")\n",
    "        print(f\"   GARCH Status: {summary['garch_summary']['status']}\")\n",
    "        if 'arima_order' in summary['arima_summary']:\n",
    "            print(f\"   ARIMA Order: {summary['arima_summary']['arima_order']}\")\n",
    "        print(f\"   Current MA: ${summary['arima_summary'].get('current_ma', 0):.2f}\")\n",
    "        print(f\"   Current BB Width: {summary['garch_summary'].get('current_bb_width', 0):.4f}\")\n",
    "\n",
    "print(f\"\\n🎯 ARIMA-GARCH Training Summary:\")\n",
    "print(f\"   Individual training: ✅ REQUIRED (time series models)\")\n",
    "print(f\"   Uses auto_arima for optimal order selection\")\n",
    "print(f\"   Uses GARCH(1,1) for volatility modeling\")\n",
    "print(f\"   Trained on: 20-day MA and Bollinger Band width\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step8",
   "metadata": {},
   "source": [
    "## 8. Integrate Models and Make Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6037c13-64b0-4691-bad2-15190f4d4693",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "prediction",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔮 Making prediction for A using integer regime system...\n",
      "✅ Using ARIMA-GARCH forecasts:\n",
      "   ARIMA Model: ARIMA\n",
      "   GARCH Model: GARCH\n",
      "   MA Range: $117.17 → $115.15\n",
      "   BB Width Range: 0.0322 → 0.0354\n",
      "\n",
      "🎯 Using Global Models with Integer Regime System:\n",
      "   Current Regime (Integer): trend_0 + vol_4\n",
      "   Current Regime (Labels): strong_bear + vol_4 = strong_bear_vol_4\n",
      "   Current MA: $117.46\n",
      "   Current Close: $114.89\n",
      "\n",
      "🔄 Integer-to-Label Regime Mapping:\n",
      "   trend_0 = strong_bear\n",
      "   vol_4 = vol_4\n",
      "   Combined: strong_bear_vol_4\n",
      "\n",
      "💰 PREDICTION RESULTS for A (Integer Regime System):\n",
      "   Current Price: $114.89\n",
      "   10-Day Prediction: $113.85\n",
      "   Expected Return: -0.90%\n",
      "   Average Daily Range: $2.24\n",
      "   Regime Used: strong_bear_vol_4 (trend_0_vol_4)\n",
      "\n",
      "🔧 Models Used: 5/6\n",
      "   global_markov: ✅\n",
      "   individual_markov: ❌\n",
      "   global_close_kde: ✅\n",
      "   global_open_kde: ✅\n",
      "   global_hl_copula: ✅\n",
      "   arima_garch_model: ✅\n",
      "\n",
      "✅ Training pipeline completed - 21:02:11\n",
      "\n",
      "📊 10-Day Detailed Forecast:\n",
      "Day  Open     High     Low      Close    MA       Range   \n",
      "------------------------------------------------------------\n",
      "1    $115.00  $116.78  $114.92  $116.08  $117.17  $1.85   \n",
      "2    $117.07  $118.40  $116.56  $117.32  $116.90  $1.85   \n",
      "3    $116.91  $118.51  $115.21  $117.09  $116.64  $3.30   \n",
      "4    $117.75  $118.70  $116.66  $117.46  $116.39  $2.04   \n",
      "5    $117.77  $118.86  $116.27  $117.72  $116.15  $2.59   \n",
      "6    $116.17  $117.05  $115.22  $116.07  $115.93  $1.83   \n",
      "7    $117.05  $118.03  $115.97  $116.88  $115.72  $2.06   \n",
      "8    $115.71  $116.65  $114.70  $115.48  $115.52  $1.95   \n",
      "9    $116.47  $117.72  $115.21  $116.72  $115.33  $2.51   \n",
      "10   $113.39  $115.19  $112.81  $113.85  $115.15  $2.38   \n",
      "\n",
      "🎯 Integer Regime System Summary:\n",
      "   Configuration: 7 trend × 5 vol = 35 regimes\n",
      "   Global models trained on 2298 stocks\n",
      "   Predicted using regime: trend_0 (strong_bear) + vol_4 (vol_4)\n",
      "   Target stock: A\n"
     ]
    }
   ],
   "source": [
    "print(f\"🔮 Making prediction for {target_stock} using integer regime system...\")\n",
    "\n",
    "# Get target stock data\n",
    "target_data = all_prepared_data[target_stock]\n",
    "current_close = target_data['Close'].iloc[-1]\n",
    "current_ma = target_data['MA'].iloc[-1]\n",
    "\n",
    "# Generate forecasts using new ARIMA-GARCH model\n",
    "forecast_days = 10\n",
    "\n",
    "# Use ARIMA-GARCH model if available\n",
    "if target_stock in arima_garch_models and arima_garch_models[target_stock] and arima_garch_models[target_stock].fitted:\n",
    "    arima_garch_forecast = arima_garch_models[target_stock].forecast(horizon=forecast_days)\n",
    "    \n",
    "    # Extract MA and volatility forecasts\n",
    "    ma_forecast = arima_garch_forecast['ma_forecast']\n",
    "    bb_width_forecast = arima_garch_forecast['bb_width_forecast']\n",
    "    \n",
    "    # Convert BB width to volatility for compatibility\n",
    "    vol_forecast = bb_width_forecast\n",
    "    \n",
    "    print(f\"✅ Using ARIMA-GARCH forecasts:\")\n",
    "    print(f\"   ARIMA Model: {arima_garch_forecast['arima_model_type']}\")\n",
    "    print(f\"   GARCH Model: {arima_garch_forecast['garch_model_type']}\")\n",
    "    print(f\"   MA Range: ${ma_forecast[0]:.2f} → ${ma_forecast[-1]:.2f}\")\n",
    "    print(f\"   BB Width Range: {bb_width_forecast[0]:.4f} → {bb_width_forecast[-1]:.4f}\")\n",
    "    \n",
    "else:\n",
    "    # Fallback to simple forecasts\n",
    "    ma_forecast = np.linspace(current_ma, current_ma * 1.01, forecast_days)\n",
    "    vol_forecast = np.full(forecast_days, 0.025)\n",
    "    print(\"⚠️ Using fallback MA and volatility forecasts\")\n",
    "\n",
    "# Generate predictions using global models with integer regime system\n",
    "print(f\"\\n🎯 Using Global Models with Integer Regime System:\")\n",
    "\n",
    "# Determine current regime using integer states\n",
    "from models.regime_classifier import REGIME_CLASSIFIER\n",
    "\n",
    "current_returns = target_data['Close'].pct_change().tail(20)\n",
    "ma_series = target_data['MA'].tail(20)\n",
    "\n",
    "# Classify using integer regime system (both states and labels)\n",
    "trend_states = REGIME_CLASSIFIER.classify_trend(ma_series, return_states=True)\n",
    "vol_states = REGIME_CLASSIFIER.classify_volatility(current_returns, return_states=True)\n",
    "trend_labels = REGIME_CLASSIFIER.classify_trend(ma_series, return_states=False)  \n",
    "vol_labels = REGIME_CLASSIFIER.classify_volatility(current_returns, return_states=False)\n",
    "\n",
    "# Get current regime\n",
    "current_trend_state = trend_states.iloc[-1] if len(trend_states) > 0 else REGIME_CONFIG.fallback_trend_state\n",
    "current_vol_state = vol_states.iloc[-1] if len(vol_states) > 0 else REGIME_CONFIG.fallback_volatility_state\n",
    "current_trend_label = REGIME_CONFIG.trend.get_state_label(current_trend_state)\n",
    "current_vol_label = REGIME_CONFIG.volatility.get_state_label(current_vol_state)\n",
    "current_regime = f\"{current_trend_label}_{current_vol_label}\"\n",
    "\n",
    "print(f\"   Current Regime (Integer): trend_{current_trend_state} + vol_{current_vol_state}\")\n",
    "print(f\"   Current Regime (Labels): {current_trend_label} + {current_vol_label} = {current_regime}\")\n",
    "print(f\"   Current MA: ${current_ma:.2f}\")\n",
    "print(f\"   Current Close: ${current_close:.2f}\")\n",
    "\n",
    "# Show regime mapping\n",
    "print(f\"\\n🔄 Integer-to-Label Regime Mapping:\")\n",
    "print(f\"   trend_{current_trend_state} = {current_trend_label}\")\n",
    "print(f\"   vol_{current_vol_state} = {current_vol_label}\")\n",
    "print(f\"   Combined: {current_regime}\")\n",
    "\n",
    "# Generate day-by-day predictions using global models\n",
    "daily_predictions = []\n",
    "\n",
    "for day in range(forecast_days):\n",
    "    day_ma = ma_forecast[day]\n",
    "    day_vol = vol_forecast[day]\n",
    "    \n",
    "    try:\n",
    "        # Sample close price from global close KDE\n",
    "        if global_close_kde and global_close_kde.fitted:\n",
    "            close_samples = global_close_kde.sample_close_price(current_regime, day_ma, n_samples=5)\n",
    "            pred_close = np.mean(close_samples)\n",
    "        else:\n",
    "            pred_close = day_ma * (1 + np.random.normal(0, day_vol))\n",
    "        \n",
    "        # Sample gap for next day's open\n",
    "        if global_open_kde and global_open_kde.fitted and day < forecast_days - 1:\n",
    "            gap_samples = global_open_kde.sample_gap(current_regime, n_samples=5)\n",
    "            next_open = pred_close * (1 + np.mean(gap_samples))\n",
    "        else:\n",
    "            next_open = pred_close * (1 + np.random.normal(0, 0.005))\n",
    "        \n",
    "        # Sample high/low from copula\n",
    "        if global_hl_copula and global_hl_copula.fitted:\n",
    "            ref_price = (pred_close + (next_open if day < forecast_days - 1 else pred_close)) / 2\n",
    "            hl_samples = global_hl_copula.sample_high_low(current_regime, ref_price, n_samples=5)\n",
    "            pred_high = np.mean(hl_samples['high'])\n",
    "            pred_low = np.mean(hl_samples['low'])\n",
    "        else:\n",
    "            # Fallback high/low\n",
    "            pred_high = max(pred_close, next_open) * (1 + day_vol)\n",
    "            pred_low = min(pred_close, next_open) * (1 - day_vol)\n",
    "        \n",
    "        daily_predictions.append({\n",
    "            'day': day + 1,\n",
    "            'open': next_open if day > 0 else current_close * 1.001,\n",
    "            'high': pred_high,\n",
    "            'low': pred_low,\n",
    "            'close': pred_close,\n",
    "            'ma': day_ma\n",
    "        })\n",
    "        \n",
    "    except Exception as e:\n",
    "        # Fallback simple prediction\n",
    "        pred_close = day_ma * (1 + np.random.normal(0, 0.01))\n",
    "        daily_predictions.append({\n",
    "            'day': day + 1,\n",
    "            'open': pred_close * 1.001,\n",
    "            'high': pred_close * 1.01,\n",
    "            'low': pred_close * 0.99,\n",
    "            'close': pred_close,\n",
    "            'ma': day_ma\n",
    "        })\n",
    "\n",
    "# Calculate summary metrics\n",
    "final_price = daily_predictions[-1]['close']\n",
    "total_return = (final_price - current_close) / current_close * 100\n",
    "avg_daily_range = np.mean([pred['high'] - pred['low'] for pred in daily_predictions])\n",
    "\n",
    "print(f\"\\n💰 PREDICTION RESULTS for {target_stock} (Integer Regime System):\")\n",
    "print(f\"   Current Price: ${current_close:.2f}\")\n",
    "print(f\"   {forecast_days}-Day Prediction: ${final_price:.2f}\")\n",
    "print(f\"   Expected Return: {total_return:.2f}%\")\n",
    "print(f\"   Average Daily Range: ${avg_daily_range:.2f}\")\n",
    "print(f\"   Regime Used: {current_regime} (trend_{current_trend_state}_vol_{current_vol_state})\")\n",
    "\n",
    "# Model utilization summary\n",
    "models_used = {\n",
    "    'global_markov': global_markov.fitted if hasattr(global_markov, 'fitted') else True,\n",
    "    'individual_markov': target_stock in individual_markov,\n",
    "    'global_close_kde': global_close_kde is not None and global_close_kde.fitted,\n",
    "    'global_open_kde': global_open_kde is not None and global_open_kde.fitted,\n",
    "    'global_hl_copula': global_hl_copula is not None and global_hl_copula.fitted,\n",
    "    'arima_garch_model': target_stock in arima_garch_models and arima_garch_models[target_stock] and arima_garch_models[target_stock].fitted\n",
    "}\n",
    "\n",
    "print(f\"\\n🔧 Models Used: {sum(models_used.values())}/6\")\n",
    "for model, used in models_used.items():\n",
    "    status = '✅' if used else '❌'\n",
    "    print(f\"   {model}: {status}\")\n",
    "\n",
    "print(f\"\\n✅ Training pipeline completed - {datetime.now().strftime('%H:%M:%S')}\")\n",
    "\n",
    "# Show detailed forecast table\n",
    "if len(daily_predictions) > 0:\n",
    "    print(f\"\\n📊 {forecast_days}-Day Detailed Forecast:\")\n",
    "    print(f\"{'Day':<4} {'Open':<8} {'High':<8} {'Low':<8} {'Close':<8} {'MA':<8} {'Range':<8}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    for pred in daily_predictions:\n",
    "        day = pred['day']\n",
    "        open_p = pred['open']\n",
    "        high_p = pred['high']\n",
    "        low_p = pred['low']\n",
    "        close_p = pred['close']\n",
    "        ma_p = pred['ma']\n",
    "        range_p = high_p - low_p\n",
    "        \n",
    "        print(f\"{day:<4} ${open_p:<7.2f} ${high_p:<7.2f} ${low_p:<7.2f} ${close_p:<7.2f} ${ma_p:<7.2f} ${range_p:<7.2f}\")\n",
    "\n",
    "print(f\"\\n🎯 Integer Regime System Summary:\")\n",
    "print(f\"   Configuration: {N_TREND_STATES} trend × {N_VOL_STATES} vol = {N_TREND_STATES * N_VOL_STATES} regimes\")\n",
    "print(f\"   Global models trained on {len(all_prepared_data)} stocks\")\n",
    "print(f\"   Predicted using regime: trend_{current_trend_state} ({current_trend_label}) + vol_{current_vol_state} ({current_vol_label})\")\n",
    "print(f\"   Target stock: {target_stock}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "**Training Completed with Global Models + Individual ARIMA-GARCH:**\n",
    "1. ✅ **Regime Configuration**: Integer states configured at pipeline start\n",
    "2. ✅ **Global Markov Model**: Trained on all stocks with sparse bucket diagnostics \n",
    "3. ✅ **Global-Only Training**: Removed per-stock Markov models for robustness\n",
    "4. ✅ **Close Price KDE Models**: Global training with integer regime resolution\n",
    "5. ✅ **Open Price Models**: Global KDE with trend/volatility resolution\n",
    "6. ✅ **High/Low Copula Models**: Global copula with regime resolution\n",
    "7. ✅ **Individual ARIMA-GARCH Models**: Per-stock time series models (required)\n",
    "8. ✅ **Integrated Prediction**: Using integer regime system for forecasting\n",
    "9. ✅ **Markov Heatmap Visualization**: Transition matrix visualization added\n",
    "10. ✅ **OHLC Trajectory Visualization**: Candlestick chart visualization added\n",
    "\n",
    "**Key Features of Updated Pipeline:**\n",
    "- **Mixed training approach**: Global for regime models, individual for time series\n",
    "- **Sparse bucket diagnostics**: Identifies least populated (trend, BB-position) buckets\n",
    "- **Integer-based regimes**: trend_0, trend_1, ..., vol_0, vol_1, ...\n",
    "- **Flexible configuration**: Easy to change number of states at top\n",
    "- **State-label conversion**: Both integer states and descriptive labels\n",
    "- **Visualization capabilities**: Built-in Markov heatmaps and OHLC trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "detailed_forecast",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline complete - integer regime system successfully integrated!\n",
    "print(\"🎉 Streamlined Training Pipeline with Integer Regime System Complete!\")\n",
    "print(\"=\" * 70)\n",
    "print(\"✅ All models trained using the new integer-based regime configuration\")\n",
    "print(\"✅ Regimes can be easily modified by changing N_TREND_STATES and N_VOL_STATES\")\n",
    "print(\"✅ Both integer states and descriptive labels are supported\")\n",
    "print(\"✅ Backwards compatibility maintained with existing code\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nuwcfgsn4c",
   "metadata": {},
   "source": [
    "## Visualizations\n",
    "\n",
    "**New visualization capabilities added to the pipeline!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "h7wjwxtxqva",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# VISUALIZATION 1: Markov Transition Matrix Heatmap\n",
    "# =============================================================================\n",
    "\n",
    "print(\"🎨 Creating Markov Transition Matrix Heatmap...\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Create a visualization of the global Markov transition matrix\n",
    "if global_markov and global_markov.fitted:\n",
    "    # Set up the plot\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(12, 10))\n",
    "    \n",
    "    # Create heatmap of transition matrix\n",
    "    transition_matrix = global_markov.transition_matrix\n",
    "    state_labels = global_markov.states\n",
    "    \n",
    "    # Truncate labels for readability if too many states\n",
    "    if len(state_labels) > 10:\n",
    "        display_labels = [label[:15] + '...' if len(label) > 15 else label for label in state_labels]\n",
    "    else:\n",
    "        display_labels = state_labels\n",
    "    \n",
    "    sns.heatmap(\n",
    "        transition_matrix,\n",
    "        xticklabels=display_labels,\n",
    "        yticklabels=display_labels, \n",
    "        annot=True if len(state_labels) <= 10 else False,  # Only annotate if not too many states\n",
    "        fmt='.3f',\n",
    "        cmap='Blues',\n",
    "        ax=ax,\n",
    "        cbar_kws={'label': 'Transition Probability'},\n",
    "        square=True\n",
    "    )\n",
    "    \n",
    "    ax.set_title(f'Global Markov Transition Matrix\\n({len(state_labels)} Combined Regimes)', \n",
    "                fontsize=14, fontweight='bold')\n",
    "    ax.set_xlabel('Next State', fontsize=12)\n",
    "    ax.set_ylabel('Current State', fontsize=12)\n",
    "    \n",
    "    # Rotate labels for better readability\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"✅ Markov transition matrix heatmap displayed\")\n",
    "    print(f\"   Matrix size: {transition_matrix.shape[0]}×{transition_matrix.shape[1]}\")\n",
    "    print(f\"   Combined regimes: {len(state_labels)}\")\n",
    "    \n",
    "else:\n",
    "    print(\"❌ No global Markov model available for visualization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ki55x6s38od",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# VISUALIZATION 2: OHLC Trajectory Candlestick Chart\n",
    "# =============================================================================\n",
    "\n",
    "print(\"🎨 Creating OHLC Trajectory Candlestick Chart...\")\n",
    "\n",
    "from matplotlib.patches import Rectangle\n",
    "from matplotlib.dates import DateFormatter, DayLocator\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Generate a complete OHLC trajectory using all trained models\n",
    "forecast_days_viz = 20  # Number of days for visualization\n",
    "viz_target = target_stock\n",
    "\n",
    "print(f\"🎯 Generating {forecast_days_viz}-day OHLC trajectory for {viz_target}\")\n",
    "\n",
    "# Use the daily predictions we already calculated, or generate new ones\n",
    "if len(daily_predictions) < forecast_days_viz:\n",
    "    print(\"   Generating additional predictions for visualization...\")\n",
    "    \n",
    "    # Extend predictions if needed\n",
    "    viz_predictions = daily_predictions.copy()\n",
    "    \n",
    "    for day in range(len(daily_predictions), forecast_days_viz):\n",
    "        # Generate simple prediction for visualization\n",
    "        if day == 0:\n",
    "            prev_close = current_close\n",
    "        else:\n",
    "            prev_close = viz_predictions[-1]['close']\n",
    "        \n",
    "        # Simple random walk with trend\n",
    "        trend_factor = 0.001 if current_regime.find('bull') >= 0 else (-0.001 if current_regime.find('bear') >= 0 else 0)\n",
    "        close_price = prev_close * (1 + trend_factor + np.random.normal(0, 0.015))\n",
    "        open_price = prev_close * (1 + np.random.normal(0, 0.005))  # Small gap\n",
    "        high_price = max(open_price, close_price) * (1 + np.random.uniform(0.005, 0.015))\n",
    "        low_price = min(open_price, close_price) * (1 - np.random.uniform(0.005, 0.015))\n",
    "        \n",
    "        viz_predictions.append({\n",
    "            'day': day + 1,\n",
    "            'open': open_price,\n",
    "            'high': high_price,\n",
    "            'low': low_price,\n",
    "            'close': close_price,\n",
    "            'ma': close_price * 0.98  # Approximate MA\n",
    "        })\n",
    "else:\n",
    "    viz_predictions = daily_predictions[:forecast_days_viz]\n",
    "\n",
    "print(f\"   Generated {len(viz_predictions)} days of OHLC data\")\n",
    "\n",
    "# Create the candlestick chart\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(15, 10), height_ratios=[3, 1], sharex=True)\n",
    "\n",
    "# Generate dates for the forecast\n",
    "start_date = datetime.now().date() + timedelta(days=1)\n",
    "dates = [start_date + timedelta(days=i) for i in range(len(viz_predictions))]\n",
    "\n",
    "# Plot candlesticks\n",
    "for i, (pred, date) in enumerate(zip(viz_predictions, dates)):\n",
    "    open_price = pred['open']\n",
    "    high_price = pred['high'] \n",
    "    low_price = pred['low']\n",
    "    close_price = pred['close']\n",
    "    \n",
    "    # Determine candle color\n",
    "    color = 'green' if close_price > open_price else 'red'\n",
    "    edge_color = 'darkgreen' if close_price > open_price else 'darkred'\n",
    "    \n",
    "    # Draw high-low line\n",
    "    ax1.plot([i, i], [low_price, high_price], color=edge_color, linewidth=1.5)\n",
    "    \n",
    "    # Draw candle body\n",
    "    body_height = abs(close_price - open_price)\n",
    "    body_bottom = min(open_price, close_price)\n",
    "    \n",
    "    candle = Rectangle((i - 0.3, body_bottom), 0.6, body_height,\n",
    "                      facecolor=color, edgecolor=edge_color, alpha=0.8)\n",
    "    ax1.add_patch(candle)\n",
    "\n",
    "# Plot moving average line\n",
    "ma_values = [pred['ma'] for pred in viz_predictions]\n",
    "ax1.plot(range(len(viz_predictions)), ma_values, color='blue', linewidth=2, alpha=0.7, label='20-day MA')\n",
    "\n",
    "# Format main chart\n",
    "ax1.set_title(f'Simulated OHLC Trajectory for {viz_target}\\nUsing Global Models with Regime: {current_regime}', \n",
    "             fontsize=14, fontweight='bold')\n",
    "ax1.set_ylabel('Price ($)', fontsize=12)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.legend()\n",
    "\n",
    "# Format y-axis as currency\n",
    "ax1.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'${x:.2f}'))\n",
    "\n",
    "# Plot daily ranges in subplot\n",
    "daily_ranges = [pred['high'] - pred['low'] for pred in viz_predictions]\n",
    "ax2.bar(range(len(viz_predictions)), daily_ranges, color='purple', alpha=0.6)\n",
    "ax2.set_ylabel('Daily Range ($)', fontsize=10)\n",
    "ax2.set_xlabel('Forecast Day', fontsize=12)\n",
    "ax2.set_title('Daily Price Ranges', fontsize=12)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Format x-axis\n",
    "ax2.set_xticks(range(0, len(viz_predictions), max(1, len(viz_predictions)//10)))\n",
    "ax2.set_xticklabels([f'Day {i+1}' for i in range(0, len(viz_predictions), max(1, len(viz_predictions)//10))])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"✅ OHLC trajectory candlestick chart displayed\")\n",
    "print(f\"   Forecast period: {forecast_days_viz} days\")\n",
    "print(f\"   Target stock: {viz_target}\")\n",
    "print(f\"   Using regime: {current_regime}\")\n",
    "print(f\"   Price range: ${min([p['low'] for p in viz_predictions]):.2f} - ${max([p['high'] for p in viz_predictions]):.2f}\")\n",
    "\n",
    "# Summary statistics\n",
    "total_return_viz = (viz_predictions[-1]['close'] - viz_predictions[0]['open']) / viz_predictions[0]['open'] * 100\n",
    "avg_daily_range_viz = np.mean(daily_ranges)\n",
    "max_daily_range_viz = np.max(daily_ranges)\n",
    "\n",
    "print(f\"\\n📊 Trajectory Statistics:\")\n",
    "print(f\"   Total simulated return: {total_return_viz:.2f}%\")\n",
    "print(f\"   Average daily range: ${avg_daily_range_viz:.2f}\")\n",
    "print(f\"   Maximum daily range: ${max_daily_range_viz:.2f}\")\n",
    "print(f\"   Volatility estimate: {np.std([p['close']/viz_predictions[max(0,i-1)]['close']-1 for i, p in enumerate(viz_predictions[1:])]) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f738270d-7b53-4d3f-8c7a-7a533bba9506",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
